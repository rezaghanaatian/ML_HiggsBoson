{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import least_squares_GD, least_squares_SGD, least_squares, ridge_regression\n",
    "from helpers import load_csv_data, predict_labels, create_csv_submission, pre_process_data, normalize_data_features, \\\n",
    "    pre_process_data_jets, load_csv_data_general\n",
    "import numpy as np\n",
    "from validation import split_data, validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/train.csv\"\n",
    "data = load_csv_data_general(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalized = normalize_data_features(data.copy())   # Decreased the accuracy!!! so we do not use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_lambda(data):\n",
    "    folds_n = 10\n",
    "    parameters = [1, 0.9, 0.7, 0.5, 0.2, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001]\n",
    "    param_results = []\n",
    "    for param in parameters:\n",
    "        validation_scores = []\n",
    "        for i in range(0, folds_n):\n",
    "            x_tr, x_te = split_data(data, 1 / folds_n)\n",
    "\n",
    "            # Start ML algorithm.\n",
    "            loss, w = ridge_regression(x_tr[:, 1], x_tr[:, 2:], param)\n",
    "\n",
    "            # Test algorithm\n",
    "            y_te_predicted = predict_labels(w, x_te[:, 2:])\n",
    "            score = validate(y_te_predicted, x_te[:, 1])\n",
    "            validation_scores.append(score)\n",
    "\n",
    "        cv_score = np.mean(np.array(validation_scores))\n",
    "        param_results.append(cv_score)\n",
    "    \n",
    "    return parameters[param_results.index(np.max(np.array(param_results)))]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda0: 0.0001\n",
      "lambda0_wm: 1\n",
      "lambda1: 1e-06\n",
      "lambda1_wm: 0.0001\n",
      "lambda2: 0.001\n",
      "lambda2_wm: 0.5\n",
      "lambda3: 0.01\n",
      "lambda3_wm: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Find best hyper parameters of the algorithm.\n",
    "x_tr0, x_tr1, x_tr2, x_tr3, x_tr0_wm, x_tr1_wm, x_tr2_wm, x_tr3_wm = pre_process_data_jets(data)\n",
    "\n",
    "lambda0 = find_best_lambda(x_tr0)\n",
    "lambda0_wm = find_best_lambda(x_tr0_wm)\n",
    "lambda1 = find_best_lambda(x_tr1)\n",
    "lambda1_wm = find_best_lambda(x_tr1_wm)\n",
    "lambda2 = find_best_lambda(x_tr2)\n",
    "lambda2_wm = find_best_lambda(x_tr2_wm)\n",
    "lambda3 = find_best_lambda(x_tr3)\n",
    "lambda3_wm = find_best_lambda(x_tr3_wm)\n",
    "\n",
    "print(\"lambda0: \" + str(lambda0))\n",
    "print(\"lambda0_wm: \" + str(lambda0_wm))\n",
    "print(\"lambda1: \" + str(lambda1))\n",
    "print(\"lambda1_wm: \" + str(lambda1_wm))\n",
    "print(\"lambda2: \" + str(lambda2))\n",
    "print(\"lambda2_wm: \" + str(lambda2_wm))\n",
    "print(\"lambda3: \" + str(lambda3))\n",
    "print(\"lambda3_wm: \" + str(lambda3_wm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_n = 1    #Put it 1 if you want to generate output for Kaggle! if you want to do local cross validation put it a number(for example 10)\n",
    "validation_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, folds_n):\n",
    "\n",
    "    if folds_n > 1:\n",
    "        x_tr, x_te = split_data(data, 1 / folds_n)\n",
    "    else:\n",
    "        test_data_path = \"data/test.csv\"\n",
    "        test_data = load_csv_data_general(test_data_path)\n",
    "        x_tr = data\n",
    "        x_te = test_data\n",
    "\n",
    "    x_tr0, x_tr1, x_tr2, x_tr3, x_tr0_wm, x_tr1_wm, x_tr2_wm, x_tr3_wm = pre_process_data_jets(x_tr)\n",
    "    # Start ML algorithm.\n",
    "    loss0, w0 = ridge_regression(x_tr0[:, 1], x_tr0[:, 2:], lambda0)\n",
    "    loss1, w1 = ridge_regression(x_tr1[:, 1], x_tr1[:, 2:], lambda1)\n",
    "    loss2, w2 = ridge_regression(x_tr2[:, 1], x_tr2[:, 2:], lambda2)\n",
    "    loss3, w3 = ridge_regression(x_tr3[:, 1], x_tr3[:, 2:], lambda3)\n",
    "    loss0_wm, w0_wm = ridge_regression(x_tr0_wm[:, 1], x_tr0_wm[:, 2:], lambda0_wm)\n",
    "    loss1_wm, w1_wm = ridge_regression(x_tr1_wm[:, 1], x_tr1_wm[:, 2:], lambda1_wm)\n",
    "    loss2_wm, w2_wm = ridge_regression(x_tr2_wm[:, 1], x_tr2_wm[:, 2:], lambda2_wm)\n",
    "    loss3_wm, w3_wm = ridge_regression(x_tr3_wm[:, 1], x_tr3_wm[:, 2:], lambda3_wm)\n",
    "\n",
    "    # Test algorithm\n",
    "    x_te0, x_te1, x_te2, x_te3, x_te0_wm, x_te1_wm, x_te2_wm, x_te3_wm = pre_process_data_jets(x_te)\n",
    "    y_te_predicted0 = predict_labels(w0, x_te0[:, 2:])\n",
    "    y_te_predicted1 = predict_labels(w1, x_te1[:, 2:])\n",
    "    y_te_predicted2 = predict_labels(w2, x_te2[:, 2:])\n",
    "    y_te_predicted3 = predict_labels(w3, x_te3[:, 2:])\n",
    "    y_te_predicted0_wm = predict_labels(w0_wm, x_te0_wm[:, 2:])\n",
    "    y_te_predicted1_wm = predict_labels(w1_wm, x_te1_wm[:, 2:])\n",
    "    y_te_predicted2_wm = predict_labels(w2_wm, x_te2_wm[:, 2:])\n",
    "    y_te_predicted3_wm = predict_labels(w3_wm, x_te3_wm[:, 2:])\n",
    "\n",
    "    if folds_n > 1:\n",
    "        score0 = validate(y_te_predicted0, x_te0[:, 1])\n",
    "        score1 = validate(y_te_predicted1, x_te1[:, 1])\n",
    "        score2 = validate(y_te_predicted2, x_te2[:, 1])\n",
    "        score3 = validate(y_te_predicted3, x_te3[:, 1])\n",
    "        score0_wm = validate(y_te_predicted0_wm, x_te0_wm[:, 1])\n",
    "        score1_wm = validate(y_te_predicted1_wm, x_te1_wm[:, 1])\n",
    "        score2_wm = validate(y_te_predicted2_wm, x_te2_wm[:, 1])\n",
    "        score3_wm = validate(y_te_predicted3_wm, x_te3_wm[:, 1])\n",
    "\n",
    "        # validation_scores.append(score)\n",
    "        print(\"Accuracy score-jet0:\" + str(score0))\n",
    "        print(\"Accuracy score-jet1:\" + str(score1))\n",
    "        print(\"Accuracy score-jet2:\" + str(score2))\n",
    "        print(\"Accuracy score-jet3:\" + str(score3))\n",
    "        print(\"Accuracy score-jet0_wm:\" + str(score0_wm))\n",
    "        print(\"Accuracy score-jet1_wm:\" + str(score1_wm))\n",
    "        print(\"Accuracy score-jet2_wm:\" + str(score2_wm))\n",
    "        print(\"Accuracy score-jet3_wm:\" + str(score3_wm))\n",
    "        final_score = (score0 * len(y_te_predicted0) + score1 * len(y_te_predicted1) + score2 * len(\n",
    "            y_te_predicted2) + score3 * len(y_te_predicted3) +\n",
    "                       score0_wm * len(y_te_predicted0_wm) + score1_wm * len(y_te_predicted1_wm) + score2_wm * len(\n",
    "            y_te_predicted2_wm) + score3_wm * len(y_te_predicted3_wm)) / (\n",
    "                          len(y_te_predicted0) + len(y_te_predicted1) + len(y_te_predicted2) + len(y_te_predicted3) +\n",
    "                          len(y_te_predicted0_wm) + len(y_te_predicted1_wm) + len(y_te_predicted2_wm) + len(\n",
    "                              y_te_predicted3_wm))\n",
    "\n",
    "        print(\"================ step \" + str(i + 1) + \" : \" + str(final_score) + \" ================\")\n",
    "\n",
    "        validation_scores.append(final_score)\n",
    "    else:\n",
    "        # Extract prediction to upload in Kaggle\n",
    "        create_csv_submission(np.concatenate((x_te0[:, 0], x_te1[:, 0], x_te2[:, 0], x_te3[:, 0], x_te0_wm[:, 0],\n",
    "                                              x_te1_wm[:, 0], x_te2_wm[:, 0], x_te3_wm[:, 0])),\n",
    "                              np.concatenate((y_te_predicted0, y_te_predicted1, y_te_predicted2, y_te_predicted3,\n",
    "                                              y_te_predicted0_wm, y_te_predicted1_wm, y_te_predicted2_wm,\n",
    "                                              y_te_predicted3_wm)),\n",
    "                              \"output\")\n",
    "\n",
    "if folds_n > 1:\n",
    "    cv_score = np.mean(np.array(validation_scores))\n",
    "    print(\"================ Final validation Score ================\")\n",
    "    print(\"MEAN-Accuracy score:\" + str(cv_score))\n",
    "    \n",
    "else:\n",
    "    print(\"================ Output generated successfully in output folder! ================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
